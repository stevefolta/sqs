#!/usr/bin/env sqs

# Lexer.

import Debugging

# Lexer globals.
id = r"([[:alpha:]][[:alnum:]_-]*)|\$" 	# TODO: unicode.
operator = r"\+=?|-=?|\*=?|/=?|%=?|\^=?|&(&|=)?|\|(\||=)?|\(|\)|\[|\]|\{|\}|==?|!=?|\.|,|:|~|<<?=?|>>?=?"
num = r"-?(0x)?[0-9]+(\.[0-9]+)?"
integer = r"-?(0x)?[0-9]+"
float-pattern = r"-?(0x)?[0-9]+\.[0-9]+"
double-quote-string = r'r?"(\\.|[^"])*"'
single-quote-string = r"r?'(\\.|[^'])*'"
backquote-string = r"r?`(\\.|[^`])*`"
double-quote-string-contents = r'(\\.|[^"])*'
single-quote-string-contents = r"(\\.|[^'])*"
backquote-string-contents = r"(\\.|[^`])*"
double-quote-string-start-re = Regex('^[ \t]*(r?"{double-quote-string-contents})$')
single-quote-string-start-re = Regex("^[ \t]*(r?'{single-quote-string-contents})$")
backquote-string-start-re = Regex("^[ \t]*(r?`{backquote-string-contents})$")
string-start-re = Regex("^[ \t]*(r?(\"{double-quote-string-contents}|'{single-quote-string-contents}|`{backquote-string-contents}))$")
double-quote-string-end-re = Regex('{double-quote-string-contents}"')
single-quote-string-end-re = Regex("{single-quote-string-contents}'")
backquote-string-end-re = Regex("{backquote-string-contents}`")
token-re = Regex("^[ \t]*({id}|{num}|{operator}|{double-quote-string}|{single-quote-string}|{backquote-string})")
indentation-re = Regex(r"^([[:space:]]*).*$")
ignore-re = Regex(r"^[[:space:]]*(#.+)?$")
leading-whitespace-re = Regex(r"^[[:space:]]*")

# Exported regular expressions.
identifier-re-var = Regex("^{id}$")
operator-re-var = Regex("^({operator})$")
string-literal-re-var = Regex("^({double-quote-string}|{single-quote-string}|{backquote-string})$")
integer-re-var = Regex("^{integer}$")
float-re-var = Regex("^{float-pattern}$")
export fn operator-re
	return operator-re-var
export fn identifier-re
	return identifier-re-var
export fn string-literal-re
	return string-literal-re-var
export fn integer-re
	return integer-re-var
export fn float-re
	return float-re-var

# Lexer special tokens.
eol = "#eol"
indent = "#indent"
dedent = "#dedent"
export fn eol-token
	return eol
export fn indent-token
	return indent
export fn dedent-token
	return dedent

export class Lexer
	(stream filename lines cur-line peeked-token line-number)
	(indent-stack unindent-to at-line-start paren-level)

	init(stream-in, filename-in)
		stream = stream-in
		filename = filename-in
		lines = stream.lines
		cur-line = lines.next
		line-number = 1
		indent-stack = []
		unindent-to = -1
		at-line-start = true
		paren-level = 0

	is-for-expression(line-number-in)
		at-line-start = false
		line-number = line-number-in

	next
		if peeked-token
			result = peeked-token
			peeked-token = nil
			return result
		return next-token

	peek
		if !peeked-token
			peeked-token = next-token
		return peeked-token

	next-token
		# EOF?
		if !cur-line
			if indent-stack.size > 0
				unindent-to = 0
			else
				return nil

		# Unindenting?
		token = check-unindent
		if token
			return token

		# Indenting?
		if at-line-start && paren-level == 0
			at-line-start = false

			# Consume empty lines before looking at indentation.
			while true
				if !ignore-re.match(cur-line)
					break
				cur-line = lines.next
				line-number += 1
				if !cur-line
					unindent-to = 0
					return check-unindent

			# Figure out the indentation change.
			token = indentation-change
			if token
				return token

		# End of line?
		if ignore-re.match(cur-line)
			# Move to the next line.
			cur-line = lines.next
			line-number += 1
			at-line-start = true
			if paren-level > 0
				while ignore-re.match(cur-line)
					cur-line = lines.next
					line-number += 1
			else
				return eol

		# Next real token.
		if string-start-re.match(cur-line)
			return lex-multiline-string
		match = token-re.match(cur-line)
		if !match
			fail("Unknown characters on line {line-number}: {cur-line}")
		cur-line = match.remainder
		token = match[1]
		if token == "(" || token == "[" || token == r"{"
			paren-level += 1
		else if token == ")" || token == "]" || token == "}"
			paren-level -= 1
		at-line-start = false
		return token

	next-raw-line
		# EOF?
		if !cur-line
			if indent-stack.size > 0
				unindent-to = 0
			else
				return nil

		# Unindenting?
		token = check-unindent
		if token
			return token

		# Empty line?
		match = leading-whitespace-re.match(cur-line)
		if match && match.remainder.is-empty
			cur-line = lines.next
			line-number += 1
			at-line-start = true
			return ""

		# Indentation change?
		token = indentation-change
		if token
			return token

		# Return the line.
		line = cur-line
		if match
			line = match.remainder
		cur-line = lines.next
		line-number += 1
		at-line-start = true
		return line

	check-unindent
		if unindent-to >= 0
			if indent-stack.size == 0 || unindent-to == indent-stack.back
				# We're done unindenting.
				unindent-to = -1
			else
				# Unindent one more level.
				indent-stack.pop-back
				return dedent

	indentation-change
		# Figure out the indentation change.
		indentation = indentation-re.match(cur-line)[1].size
		if (indentation > 0 && indent-stack.size == 0) || indentation > indent-stack.back
			indent-stack.append(indentation)
			return indent
		else if indent-stack.size > 0 && indentation < indent-stack.back
			unindent-to = indentation
			indent-stack.pop-back
			return dedent
		return nil

	lex-multiline-string
		end-re = double-quote-string-end-re
		if single-quote-string-start-re.match(cur-line)
			end-re = single-quote-string-end-re
		else if backquote-string-start-re.match(cur-line)
			end-re = backquote-string-end-re
		quote-lines = [ string-start-re.match(cur-line)[1] ]
		while true
			cur-line = lines.next
			match = end-re.match(cur-line)
			if match
				quote-lines.append(match[0])
				cur-line = match.remainder
				break
			else
				quote-lines.append(cur-line)
		return quote-lines.join("\n")

	where
		if filename
			return 'on line {line-number} of "{filename}"'
		return 'on line {line-number}'

	test
		while true
			token = next
			if !token
				break
			print("{line-number}: {token}")



